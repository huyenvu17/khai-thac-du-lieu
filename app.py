import streamlit as st
import pandas as pd
from src.utils import load_csv
from src.kmeans import run_kmeans, plot_clusters, plot_elbow_method, plot_cluster_stats
from src.naive_bayes import run_nb
from src.decision_tree_cart import run_dt_cart
from src.decision_tree_id3 import run_dt_id3
from src.decision_tree_quinlan import run_dt_quinlan
from src.apriori import run_apriori
from src.roughset import reduce_attributes


st.set_page_config(page_title="·ª®ng D·ª•ng Khai Th√°c D·ªØ Li·ªáu Trong Lƒ©nh V·ª±c B√°n H√†ng", layout="wide")


@st.cache_data
def load_fashion_retail_data() -> pd.DataFrame:
    try:
        return load_csv("data/datasets/Fashion_Retail_Sales_one.csv")
    except Exception:
        return pd.DataFrame()

@st.cache_data
def load_default_customers() -> pd.DataFrame:
    try:
        return load_csv("data/datasets/customers.csv")
    except Exception:
        return pd.DataFrame()


def sidebar_controls():
    st.sidebar.header("Ch·ªçn thu·∫≠t to√°n")
    algo = st.sidebar.selectbox(
        "Thu·∫≠t to√°n",
        [
            "Apriori",
            "K-means", 
            "Naive Bayes",
            "Decision-Tree-CART",
            "Decision-Tree-ID3",
            "Decision-Tree-Quinlan",
            "Rough Set",
        ],
    )

    st.sidebar.header("D·ªØ li·ªáu")
    data_choice = st.sidebar.radio("Ngu·ªìn d·ªØ li·ªáu", ["M·∫∑c ƒë·ªãnh", "T·∫£i CSV"])
    uploaded = None
    if data_choice == "T·∫£i CSV":
        uploaded = st.sidebar.file_uploader("Ch·ªçn file CSV", type=["csv"]) 

    return algo, uploaded


def main():
    st.title("·ª®ng D·ª•ng Khai Th√°c D·ªØ Li·ªáu Trong Lƒ©nh V·ª±c B√°n H√†ng")
    st.write("Ch·ªçn thu·∫≠t to√°n v√† tham s·ªë ·ªü sidebar. K·∫øt qu·∫£ hi·ªÉn th·ªã ·ªü ƒë√¢y.")

    algo, uploaded = sidebar_controls()

    # Load data theo thu·∫≠t to√°n
    data_df = pd.DataFrame()
    if uploaded is not None:
        data_df = pd.read_csv(uploaded)
    else:
        data_df = load_fashion_retail_data()
    
    if data_df.empty:
        st.warning("Kh√¥ng t√¨m th·∫•y d·ªØ li·ªáu Fashion Retail Sales. H√£y t·∫£i CSV ho·∫∑c th√™m v√†o data/datasets/Fashion_Retail_Sales.csv")
        return

    st.subheader("D·ªØ li·ªáu s·ª≠ d·ª•ng")
    with st.expander("üìä Xem d·ªØ li·ªáu Fashion Retail Sales", expanded=False):
        st.dataframe(data_df)

    # Hi·ªÉn th·ªã d·ªØ li·ªáu ƒë·∫ßu v√†o cho thu·∫≠t to√°n ƒë∆∞·ª£c ch·ªçn
    if algo == "K-means":
        # Chu·∫©n b·ªã d·ªØ li·ªáu cho K-means theo m√πa
        if 'Date Purchase' in data_df.columns and 'Purchase Amount (USD)' in data_df.columns:
            # T·∫°o c·ªôt Quarter t·ª´ Date Purchase
            kmeans_data = data_df.copy()
            kmeans_data['Date Purchase'] = pd.to_datetime(kmeans_data['Date Purchase'], format='%d-%m-%Y')
            kmeans_data['Quarter'] = kmeans_data['Date Purchase'].dt.quarter
            
            # Ch·ªçn features cho K-means
            feature_cols = ['Purchase Amount (USD)', 'Quarter']
            if 'Review Rating' in kmeans_data.columns:
                # X·ª≠ l√Ω missing values trong Review Rating
                kmeans_data = kmeans_data.dropna(subset=['Review Rating'])
                feature_cols.append('Review Rating')
            
            st.write("**üìã D·ªØ li·ªáu ƒë·∫ßu v√†o (K-means):**")
            kmeans_input = kmeans_data[['Customer Reference ID', 'Purchase Amount (USD)', 'Quarter'] + (['Review Rating'] if 'Review Rating' in kmeans_data.columns else [])].copy()
            st.dataframe(kmeans_input.head(20))
        else:
            st.error("D·ªØ li·ªáu kh√¥ng c√≥ c·ªôt 'Date Purchase' ho·∫∑c 'Purchase Amount (USD)'")





    # Ph·∫ßn ch·∫°y thu·∫≠t to√°n K-means
    if algo == "K-means":
        st.subheader("Chi·∫øn l∆∞·ª£c Marketing theo M√πa - K-means")
        st.write("**M·ª•c ti√™u:** Ph√¢n nh√≥m kh√°ch h√†ng theo m√πa mua h√†ng (Q1-Q4)")
        
        # Chu·∫©n b·ªã d·ªØ li·ªáu cho K-means theo m√πa
        if 'Date Purchase' in data_df.columns and 'Purchase Amount (USD)' in data_df.columns:
            # T·∫°o c·ªôt Quarter t·ª´ Date Purchase
            kmeans_data = data_df.copy()
            kmeans_data['Date Purchase'] = pd.to_datetime(kmeans_data['Date Purchase'], format='%d-%m-%Y')
            kmeans_data['Quarter'] = kmeans_data['Date Purchase'].dt.quarter
            
            # Ch·ªçn features cho K-means
            feature_cols = ['Purchase Amount (USD)', 'Quarter']
            if 'Review Rating' in kmeans_data.columns:
                # X·ª≠ l√Ω missing values trong Review Rating
                kmeans_data = kmeans_data.dropna(subset=['Review Rating'])
                feature_cols.append('Review Rating')
            
            k = st.slider("S·ªë c·ª•m theo m√πa (k)", 3, 6, 4)
            max_iter = st.slider("S·ªë v√≤ng l·∫∑p t·ªëi ƒëa", 100, 500, 300, step=50)

            if st.button("Ch·∫°y K-means"):
                # L·∫•y d·ªØ li·ªáu kh√°ch h√†ng theo quarter
                customer_seasonal = kmeans_data.groupby('Customer Reference ID').agg({
                    'Purchase Amount (USD)': 'mean',
                    'Quarter': lambda x: x.mode().iloc[0] if not x.mode().empty else x.iloc[0],
                    'Review Rating': 'mean' if 'Review Rating' in feature_cols else 'first'
                }).reset_index()
                
                # Lo·∫°i b·ªè c·ªôt Review Rating n·∫øu kh√¥ng c√≥ d·ªØ li·ªáu
                if 'Review Rating' in customer_seasonal.columns:
                    customer_seasonal = customer_seasonal.dropna(subset=['Review Rating'])
                
                labels, inertia = run_kmeans(customer_seasonal, feature_cols, k=k, max_iter=max_iter)
                st.success(f"ƒê√£ ph√¢n c·ª•m: k={k}, inertia={inertia:.2f}")
                
                # Hi·ªÉn th·ªã k·∫øt qu·∫£ ph√¢n c·ª•m
                result = customer_seasonal.copy()
                result["cluster"] = labels
                st.dataframe(result[["Customer Reference ID", *feature_cols, "cluster"]].head(20))
                
                # Th·ªëng k√™ theo c·ª•m v√† m√πa
                st.subheader("Th·ªëng k√™ theo c·ª•m m√πa v·ª•")
                cluster_stats = result.groupby("cluster")[feature_cols].mean().round(2)
                st.dataframe(cluster_stats)
                
                # Di·ªÖn gi·∫£i kinh doanh
                st.subheader("Di·ªÖn gi·∫£i kinh doanh:")
                for cluster_id in sorted(result['cluster'].unique()):
                    cluster_data = result[result['cluster'] == cluster_id]
                    avg_amount = cluster_data['Purchase Amount (USD)'].mean()
                    main_quarter = cluster_data['Quarter'].mode().iloc[0]
                    quarter_names = {1: 'Q1 (Winter)', 2: 'Q2 (Spring)', 3: 'Q3 (Summer)', 4: 'Q4 (Fall)'}
                    
                    st.write(f"‚Ä¢ **C·ª•m {cluster_id}**: {quarter_names.get(main_quarter, f'Q{main_quarter}')} - Chi ti√™u TB: ${avg_amount:.0f}")
                    st.write(f"  ‚Üí *Chi·∫øn l∆∞·ª£c:* T·∫≠p trung marketing v√†o {quarter_names.get(main_quarter, f'Q{main_quarter}')}")
                
                # Bi·ªÉu ƒë·ªì tr·ª±c quan h√≥a
                col1, col2 = st.columns(2)
                
                with col1:
                    st.subheader("Bi·ªÉu ƒë·ªì ph√¢n c·ª•m theo m√πa")
                    if len(feature_cols) >= 2:
                        fig_clusters = plot_clusters(result, feature_cols[:2], labels, k)
                        if fig_clusters:
                            st.pyplot(fig_clusters)
                
                with col2:
                    st.subheader("Elbow Method")
                    fig_elbow = plot_elbow_method(customer_seasonal, feature_cols, max_k=8)
                    st.pyplot(fig_elbow)
        else:
            st.error("D·ªØ li·ªáu kh√¥ng c√≥ c·ªôt 'Date Purchase' ho·∫∑c 'Purchase Amount (USD)'")

    elif algo == "Naive Bayes":
        st.subheader("D·ª± ƒëo√°n Rating theo Lo·∫°i S·∫£n ph·∫©m - Naive Bayes")
        st.write("**M·ª•c ti√™u:** D·ª± ƒëo√°n rating d·ª±a tr√™n lo·∫°i s·∫£n ph·∫©m v√† th√¥ng tin kh√°ch h√†ng")
        
        if 'Review Rating' in data_df.columns and 'Item Purchased' in data_df.columns:
            # Chu·∫©n b·ªã d·ªØ li·ªáu cho Naive Bayes
            nb_data = data_df.copy()
            # Lo·∫°i b·ªè missing values trong Review Rating
            nb_data = nb_data.dropna(subset=['Review Rating'])
            
            feature_cols = ['Item Purchased']
            if 'Purchase Amount (USD)' in nb_data.columns:
                feature_cols.append('Purchase Amount (USD)')
            if 'Payment Method' in nb_data.columns:
                feature_cols.append('Payment Method')
            
            # Chuy·ªÉn Review Rating th√†nh categorical target (1-5 th√†nh categories)
            nb_data['Rating_Category'] = pd.cut(nb_data['Review Rating'], 
                                               bins=[0, 2, 3, 4, 5], 
                                               labels=['Poor', 'Fair', 'Good', 'Excellent'])
            
            target = 'Rating_Category'
            
            # Hi·ªÉn th·ªã d·ªØ li·ªáu ƒë·∫ßu v√†o
            st.write("**üìã D·ªØ li·ªáu ƒë·∫ßu v√†o (Naive Bayes):**")
            nb_input = nb_data[feature_cols + [target]].copy()
            st.dataframe(nb_input.head(20))
            
            test_size = st.slider("T·ªâ l·ªá test", 0.1, 0.5, 0.2)
            
            if st.button("Ch·∫°y Naive Bayes"):
                metrics, y_pred = run_nb(nb_data, target=target, feature_columns=feature_cols, test_size=test_size)
                
                st.subheader("K·∫øt qu·∫£ d·ª± ƒëo√°n Rating:")
                st.write(f"**Accuracy:** {metrics['accuracy']:.2%}")
                st.write(f"**Precision:** {metrics['precision']:.2%}")
                st.write(f"**Recall:** {metrics['recall']:.2%}")
                st.write(f"**F1-score:** {metrics['f1_score']:.2%}")
                
                # Ma tr·∫≠n nh·∫ßm l·∫´n
                if 'confusion_matrix' in metrics:
                    st.subheader("Ma tr·∫≠n nh·∫ßm l·∫´n")
                    cm_df = pd.DataFrame(metrics['confusion_matrix'], 
                                       index=[f'Th·ª±c t·∫ø {i}' for i in range(len(metrics['confusion_matrix']))],
                                       columns=[f'D·ª± ƒëo√°n {i}' for i in range(len(metrics['confusion_matrix'][0]))])
                    st.dataframe(cm_df)
                
                # Di·ªÖn gi·∫£i kinh doanh
                st.subheader("Di·ªÖn gi·∫£i kinh doanh:")
                st.write("‚Ä¢ **M·ª•c ƒë√≠ch:** D·ª± ƒëo√°n rating ƒë·ªÉ c·∫£i thi·ªán ch·∫•t l∆∞·ª£ng s·∫£n ph·∫©m")
                st.write("‚Ä¢ **·ª®ng d·ª•ng:** T·∫≠p trung v√†o s·∫£n ph·∫©m c√≥ rating th·∫•p ƒë·ªÉ c·∫£i thi·ªán")
                st.write("‚Ä¢ **Chi·∫øn l∆∞·ª£c:** ∆Øu ti√™n ph√°t tri·ªÉn s·∫£n ph·∫©m trong category c√≥ rating cao")
        else:
            st.error("D·ªØ li·ªáu kh√¥ng c√≥ c·ªôt 'Review Rating' ho·∫∑c 'Item Purchased'")

    elif algo == "Decision-Tree-CART":
        st.subheader("K·∫ø ho·∫°ch Inventory - Decision Tree CART")
        st.write("**M·ª•c ti√™u:** Quy·∫øt ƒë·ªãnh nh·∫≠p h√†ng d·ª±a tr√™n l·ªãch s·ª≠ b√°n v√† m√πa v·ª•")
        
        if 'Purchase Amount (USD)' in data_df.columns and 'Item Purchased' in data_df.columns:
            # T·∫°o target cho inventory decision
            cart_data = data_df.copy()
            if 'Date Purchase' in cart_data.columns:
                cart_data['Date Purchase'] = pd.to_datetime(cart_data['Date Purchase'], format='%d-%m-%Y')
                cart_data['Month'] = cart_data['Date Purchase'].dt.month
            
            # T·∫°o target: 1 n·∫øu n√™n nh·∫≠p h√†ng (doanh thu cao), 0 n·∫øu kh√¥ng
            inventory_data = cart_data.groupby('Item Purchased').agg({
                'Purchase Amount (USD)': 'mean',
                'Month': lambda x: x.mode().iloc[0] if not x.mode().empty else x.iloc[0]
            }).reset_index()
            
            # T·∫°o binary target cho inventory decision
            median_amount = inventory_data['Purchase Amount (USD)'].median()
            inventory_data['Should_Restock'] = (inventory_data['Purchase Amount (USD)'] > median_amount).astype(int)
            
            feature_cols = ['Purchase Amount (USD)', 'Month']
            target = 'Should_Restock'
            
            # Hi·ªÉn th·ªã d·ªØ li·ªáu ƒë·∫ßu v√†o
            st.write("**üìã D·ªØ li·ªáu ƒë·∫ßu v√†o (Decision Tree CART):**")
            cart_input = inventory_data[feature_cols + [target]].copy()
            st.dataframe(cart_input.head(20))
            
            max_depth = st.slider("Max depth", 1, 10, 5)
            min_split = st.slider("Min samples split", 2, 10, 2)
            
            if st.button("Ch·∫°y CART"):
                metrics = run_dt_cart(inventory_data, target=target, feature_columns=feature_cols, max_depth=max_depth, min_samples_split=min_split)
                
                st.subheader("K·∫øt qu·∫£ quy·∫øt ƒë·ªãnh nh·∫≠p h√†ng:")
                st.write(f"**Accuracy:** {metrics['accuracy']:.2%}")
                
                # Di·ªÖn gi·∫£i kinh doanh
                st.subheader("Di·ªÖn gi·∫£i kinh doanh:")
                st.write("‚Ä¢ **M·ª•c ƒë√≠ch:** Quy·∫øt ƒë·ªãnh nh·∫≠p h√†ng d·ª±a tr√™n l·ªãch s·ª≠ b√°n")
                st.write("‚Ä¢ **·ª®ng d·ª•ng:** T·ªëi ∆∞u h√≥a inventory, tr√°nh t·ªìn kho")
                st.write("‚Ä¢ **Chi·∫øn l∆∞·ª£c:** T·∫≠p trung nh·∫≠p h√†ng v√†o category c√≥ doanh thu cao")
        else:
            st.error("D·ªØ li·ªáu kh√¥ng c√≥ c·ªôt 'Purchase Amount (USD)' ho·∫∑c 'Item Purchased'")

    elif algo == "Decision-Tree-ID3":
        st.subheader("Quality Control - Decision Tree ID3")
        st.write("**M·ª•c ti√™u:** Ph√¢n lo·∫°i s·∫£n ph·∫©m c√≥ v·∫•n ƒë·ªÅ d·ª±a tr√™n rating v√† feedback")
        
        if 'Review Rating' in data_df.columns and 'Item Purchased' in data_df.columns:
            # T·∫°o target cho quality control: 1 n·∫øu c√≥ v·∫•n ƒë·ªÅ (rating th·∫•p), 0 n·∫øu kh√¥ng
            quality_data = data_df.copy()
            # Lo·∫°i b·ªè missing values trong Review Rating
            quality_data = quality_data.dropna(subset=['Review Rating'])
            
            # T·∫°o binary target: 1 n·∫øu rating <= 3 (c√≥ v·∫•n ƒë·ªÅ), 0 n·∫øu rating > 3 (t·ªët)
            quality_data['Has_Quality_Issue'] = (quality_data['Review Rating'] <= 3).astype(int)
            
            feature_cols = ['Item Purchased', 'Purchase Amount (USD)']
            if 'Payment Method' in quality_data.columns:
                feature_cols.append('Payment Method')
            
            target = 'Has_Quality_Issue'
            
            # Hi·ªÉn th·ªã d·ªØ li·ªáu ƒë·∫ßu v√†o
            st.write("**üìã D·ªØ li·ªáu ƒë·∫ßu v√†o (Decision Tree ID3):**")
            id3_input = quality_data[feature_cols + [target]].copy()
            st.dataframe(id3_input.head(20))
            
            max_depth = st.slider("Max depth", 1, 10, 5)
            min_split = st.slider("Min samples split", 2, 10, 2)
            
            if st.button("Ch·∫°y ID3"):
                metrics = run_dt_id3(quality_data, target=target, feature_columns=feature_cols, max_depth=max_depth, min_samples_split=min_split)
                
                st.subheader("K·∫øt qu·∫£ ki·ªÉm so√°t ch·∫•t l∆∞·ª£ng:")
                st.write(f"**Accuracy:** {metrics['accuracy']:.2%}")
                st.write(f"**Precision:** {metrics['precision']:.2%}")
                st.write(f"**Recall:** {metrics['recall']:.2%}")
                
                # Di·ªÖn gi·∫£i kinh doanh
                st.subheader("Di·ªÖn gi·∫£i kinh doanh:")
                st.write("‚Ä¢ **M·ª•c ƒë√≠ch:** Ph√°t hi·ªán s·∫£n ph·∫©m c√≥ v·∫•n ƒë·ªÅ ch·∫•t l∆∞·ª£ng")
                st.write("‚Ä¢ **·ª®ng d·ª•ng:** Ki·ªÉm so√°t ch·∫•t l∆∞·ª£ng, c·∫£i thi·ªán s·∫£n ph·∫©m")
                st.write("‚Ä¢ **Chi·∫øn l∆∞·ª£c:** T·∫≠p trung v√†o s·∫£n ph·∫©m c√≥ rating th·∫•p ƒë·ªÉ c·∫£i thi·ªán")
        else:
            st.error("D·ªØ li·ªáu kh√¥ng c√≥ c·ªôt 'Review Rating' ho·∫∑c 'Item Purchased'")

    elif algo == "Decision-Tree-Quinlan":
        st.subheader("Seasonal Planning - Decision Tree Quinlan (C4.5)")
        st.write("**M·ª•c ti√™u:** D·ª± ƒëo√°n s·∫£n ph·∫©m ph√π h·ª£p theo qu√Ω")
        
        if 'Date Purchase' in data_df.columns and 'Item Purchased' in data_df.columns:
            # Chu·∫©n b·ªã d·ªØ li·ªáu cho seasonal planning
            seasonal_data = data_df.copy()
            seasonal_data['Date Purchase'] = pd.to_datetime(seasonal_data['Date Purchase'], format='%d-%m-%Y')
            seasonal_data['Quarter'] = seasonal_data['Date Purchase'].dt.quarter
            
            # T·∫°o target: Quarter (1-4)
            feature_cols = ['Item Purchased', 'Purchase Amount (USD)']
            if 'Review Rating' in seasonal_data.columns:
                seasonal_data = seasonal_data.dropna(subset=['Review Rating'])
                feature_cols.append('Review Rating')
            if 'Payment Method' in seasonal_data.columns:
                feature_cols.append('Payment Method')
            
            target = 'Quarter'
            
            # Hi·ªÉn th·ªã d·ªØ li·ªáu ƒë·∫ßu v√†o
            st.write("**üìã D·ªØ li·ªáu ƒë·∫ßu v√†o (Decision Tree Quinlan):**")
            quinlan_input = seasonal_data[feature_cols + [target]].copy()
            st.dataframe(quinlan_input.head(20))
            
            max_depth = st.slider("Max depth", 1, 10, 5)
            min_split = st.slider("Min samples split", 2, 10, 2)
            
            if st.button("Ch·∫°y Quinlan"):
                metrics = run_dt_quinlan(seasonal_data, target=target, feature_columns=feature_cols, max_depth=max_depth, min_samples_split=min_split)
                
                st.subheader("K·∫øt qu·∫£ d·ª± ƒëo√°n m√πa v·ª•:")
                st.write(f"**Accuracy:** {metrics['accuracy']:.2%}")
                
                # Di·ªÖn gi·∫£i kinh doanh
                st.subheader("Di·ªÖn gi·∫£i kinh doanh:")
                st.write("‚Ä¢ **M·ª•c ƒë√≠ch:** D·ª± ƒëo√°n s·∫£n ph·∫©m ph√π h·ª£p theo qu√Ω")
                st.write("‚Ä¢ **·ª®ng d·ª•ng:** K·∫ø ho·∫°ch s·∫£n ph·∫©m theo m√πa, marketing m√πa v·ª•")
                st.write("‚Ä¢ **Chi·∫øn l∆∞·ª£c:** Chu·∫©n b·ªã inventory v√† marketing ph√π h·ª£p v·ªõi t·ª´ng qu√Ω")
                
                # Hi·ªÉn th·ªã ph√¢n b·ªë theo qu√Ω
                quarter_dist = seasonal_data['Quarter'].value_counts().sort_index()
                quarter_names = {1: 'Q1 (Winter)', 2: 'Q2 (Spring)', 3: 'Q3 (Summer)', 4: 'Q4 (Fall)'}
                st.subheader("Ph√¢n b·ªë giao d·ªãch theo qu√Ω:")
                for q, count in quarter_dist.items():
                    st.write(f"‚Ä¢ **{quarter_names.get(q, f'Q{q}')}**: {count} giao d·ªãch")
        else:
            st.error("D·ªØ li·ªáu kh√¥ng c√≥ c·ªôt 'Date Purchase' ho·∫∑c 'Item Purchased'")

    elif algo == "Apriori":
        st.subheader("Thu·∫≠t To√°n Apriori (T·∫≠p ph·ªï bi·∫øn v√† lu·∫≠t li√™n k·∫øt)")
        st.write("**M·ª•c ti√™u:** Thu·∫≠t to√°n Apriori ƒë∆∞·ª£c d√πng trong b√†i to√°n ƒë·ªÉ ƒë∆∞a ra c√°c s·∫£n ph·∫©m kh√°c h√†ng th∆∞·ªùng ƒë∆∞·ª£c ch·ªçn k√®m m·ªói l·∫ßn mua s·∫Øm, t·ª´ ƒë√≥ gi√∫p ƒë∆∞a ra g·ª£i √Ω b·ªë tr√≠ s·∫£n ph·∫©m h·ª£p l√Ω ƒë·ªÉ tƒÉng hi·ªáu qu·∫£ b√°n h√†ng.")
        
        # Hi·ªÉn th·ªã d·ªØ li·ªáu ƒë·∫ßu v√†o cho Apriori
        if 'Customer Reference ID' in data_df.columns and 'Item Purchased' in data_df.columns:
            # T·∫°o transactions theo customer - m·ªói customer c√≥ nhi·ªÅu items
            transactions_df = data_df[['Customer Reference ID', 'Item Purchased']].copy()
            
            st.write("**üìã D·ªØ li·ªáu ƒë·∫ßu v√†o:**")
            st.dataframe(transactions_df)
        else:
            st.error("D·ªØ li·ªáu kh√¥ng c√≥ c·ªôt 'Customer Reference ID' ho·∫∑c 'Item Purchased'")
        
        min_sup = st.slider("Min support", 0.01, 0.2, 0.05, help="t·∫ßn s·ªë trong bao nhi√™u ph·∫ßn trƒÉm d·ªØ li·ªáu th√¨ nh·ªØng ƒëi·ªÅu ·ªü v·∫ø tr√°i v√† v·∫ø ph·∫£i c√πng x·∫£y ra")
        min_conf = st.slider("Min confidence", 0.2, 0.8, 0.4, help="ƒë·ªô m·∫°nh n·∫øu v·∫ø tr√°i x·∫£y ra th√¨ c√≥ bao nhi√™u kh·∫£ nƒÉng v·∫ø ph·∫£i x·∫£y ra")
        top_k = st.slider("S·ªë lu·∫≠t t·ªët nh·∫•t (top-k)", 3, 15, 5, help="S·ªë lu·∫≠t t·ªët nh·∫•t hi·ªÉn th·ªã")

        if st.button("Ch·∫°y Apriori"):
            # Chu·∫©n b·ªã d·ªØ li·ªáu cho Apriori: gom theo Customer ID
            if 'Customer Reference ID' in data_df.columns and 'Item Purchased' in data_df.columns:
                st.info(f"**ƒêang ph√¢n t√≠ch:** {len(transactions_df)} giao d·ªãch t·ª´ {transactions_df['Customer Reference ID'].nunique()} kh√°ch h√†ng")
                
                # T·∫°o transactions list
                transactions_list = transactions_df.groupby('Customer Reference ID')['Item Purchased'].apply(list).tolist()
                transactions_list = [items for items in transactions_list if items]  # Lo·∫°i b·ªè empty
                
                # T·∫°o One-Hot Matrix ƒë·ªÉ hi·ªÉn th·ªã
                st.write("**üî¢ Ma tr·∫≠n bi·ªÉu di·ªÖn t·∫≠p giao d·ªãch:**")
                try:
                    from mlxtend.preprocessing import TransactionEncoder
                    
                    if transactions_list:
                        te = TransactionEncoder()
                        arr = te.fit_transform(transactions_list)
                        ohe_df = pd.DataFrame(arr, columns=te.columns_)
                        ohe_df.index = [f"Customer_{i+1}" for i in range(len(ohe_df))]
                        
                        # Ch·ªâ hi·ªÉn th·ªã m·ªôt ph·∫ßn ƒë·ªÉ kh√¥ng qu√° d√†i
                        display_cols = min(10, len(ohe_df.columns))
                        st.dataframe(ohe_df.iloc[:15, :display_cols])
                        
                        if len(ohe_df.columns) > display_cols:
                            st.info(f"Hi·ªÉn th·ªã {display_cols}/{len(ohe_df.columns)} c·ªôt. T·ªïng c·ªông c√≥ {len(ohe_df)} transactions v√† {len(ohe_df.columns)} s·∫£n ph·∫©m.")
                    else:
                        st.warning("Kh√¥ng c√≥ d·ªØ li·ªáu ƒë·ªÉ t·∫°o ma tr·∫≠n")
                except Exception as e:
                    st.error(f"L·ªói t·∫°o One-Hot Matrix: {str(e)}")
                
                # Ch·∫°y thu·∫≠t to√°n Apriori               
                frequent, rules = run_apriori(transactions_df, min_support=min_sup, min_confidence=min_conf, top_k=top_k)
                
                # Hi·ªÉn th·ªã k·∫øt qu·∫£
                st.write("**üéØ T·∫≠p ph·ªï bi·∫øn th·ªèa min-support:**")
                if not frequent.empty:
                    st.dataframe(frequent.head(20))
                    st.write(f"T√¨m th·∫•y {len(frequent)} t·∫≠p ph·ªï bi·∫øn")
                else:
                    st.warning("Kh√¥ng t√¨m th·∫•y itemsets ph·ªï bi·∫øn. H√£y gi·∫£m min_support.")
                
                st.write("**üîó Lu·∫≠t li√™n k·∫øt s·∫£n ph·∫©m:**")
                if not rules.empty:
                    st.dataframe(rules)
                    
                    # Ph√¢n t√≠ch k·∫øt qu·∫£
                    st.write("**üí° Ph√¢n T√≠ch K·∫øt Qu·∫£:**")
                    for i, row in rules.iterrows():
                        st.write(f"‚Ä¢ N·∫øu kh√°ch mua **{row['antecedents']}** ‚Üí {row['confidence']:.1%} kh·∫£ nƒÉng mua **{row['consequents']}** (lift={row['lift']:.1f})")
                        st.write(f"  ‚Üí *G·ª£i √Ω:* B·ªë tr√≠ 2 s·∫£n ph·∫©m n√†y g·∫ßn nhau tr√™n k·ªá")
                else:
                    st.warning("Kh√¥ng t√¨m th·∫•y lu·∫≠t li√™n k·∫øt n√†o. H√£y th·ª≠ gi·∫£m min_support ho·∫∑c min_confidence.")
            else:
                st.error("D·ªØ li·ªáu kh√¥ng c√≥ c·ªôt 'Customer Reference ID' ho·∫∑c 'Item Purchased'")

    elif algo == "Rough Set":
        st.subheader("Ph√¢n T√≠ch Y·∫øu T·ªë ·∫¢nh H∆∞·ªüng ƒê√°nh Gi√° - Rough Set")
        st.write("**M·ª•c ti√™u:** T√¨m nh·ªØng y·∫øu t·ªë c·ªët l√µi ·∫£nh h∆∞·ªüng ƒë·∫øn vi·ªác kh√°ch h√†ng ƒë·ªÉ l·∫°i ƒë√°nh gi√° t·ªët (Review Rating cao)")
        
        if 'Review Rating' in data_df.columns:
            # Hi·ªÉn th·ªã d·ªØ li·ªáu ƒë·∫ßu v√†o
            from src.roughset import analyze_review_factors
            
            # Chu·∫©n b·ªã d·ªØ li·ªáu ƒë·ªÉ hi·ªÉn th·ªã
            analysis_data = data_df.dropna(subset=['Review Rating']).copy()
            analysis_data['High_Rating'] = (analysis_data['Review Rating'] >= 4.0).astype(int)
            
            # X·ª≠ l√Ω missing values cho c√°c c·ªôt hi·ªÉn th·ªã
            if 'Item Purchased' in analysis_data.columns:
                analysis_data['Item Purchased'] = analysis_data['Item Purchased'].fillna('Unknown')
            if 'Payment Method' in analysis_data.columns:
                analysis_data['Payment Method'] = analysis_data['Payment Method'].fillna('Unknown')
            if 'Purchase Amount (USD)' in analysis_data.columns:
                if analysis_data['Purchase Amount (USD)'].notna().any():
                    median_val = analysis_data['Purchase Amount (USD)'].median()
                    analysis_data['Purchase Amount (USD)'] = analysis_data['Purchase Amount (USD)'].fillna(median_val)
                else:
                    analysis_data['Purchase Amount (USD)'] = analysis_data['Purchase Amount (USD)'].fillna(0)
            
            # Ch·ªçn c√°c c·ªôt c·ªët l√µi ƒë·ªÉ hi·ªÉn th·ªã
            display_cols = []
            if 'Item Purchased' in analysis_data.columns:
                display_cols.append('Item Purchased')
            if 'Payment Method' in analysis_data.columns:
                display_cols.append('Payment Method')
            if 'Purchase Amount (USD)' in analysis_data.columns:
                display_cols.append('Purchase Amount (USD)')
            display_cols.extend(['Review Rating', 'High_Rating'])
            
            st.write("**üìã D·ªØ li·ªáu ƒë·∫ßu v√†o (Rough Set):**")
            st.dataframe(analysis_data[display_cols].head(20))
            
            if st.button("Ch·∫°y Rough Set"):
                # Ph√¢n t√≠ch c√°c y·∫øu t·ªë
                insights = analyze_review_factors(data_df)
                
                st.subheader("üéØ C√°c Y·∫øu T·ªë C·ªët L√µi ·∫¢nh H∆∞·ªüng ƒê√°nh Gi√°:")
                for i, factor in enumerate(insights['important_factors'], 1):
                    st.write(f"**{i}. {factor}**")
                
                # Th·ªëng k√™ t·ªïng quan
                st.subheader("üìä Th·ªëng K√™ T·ªïng Quan:")
                summary = insights['summary']
                col1, col2, col3 = st.columns(3)
                with col1:
                    st.metric("T·ªïng s·ªë ƒë√°nh gi√°", summary['total_reviews'])
                with col2:
                    st.metric("ƒê√°nh gi√° t·ªët", f"{summary['high_rating_count']} ({summary['high_rating_rate']:.1%})")
                with col3:
                    st.metric("ƒê√°nh gi√° trung b√¨nh", f"{summary['avg_rating']}/5.0")
                
                # Ph√¢n t√≠ch chi ti·∫øt t·ª´ng y·∫øu t·ªë
                st.subheader("üîç Ph√¢n T√≠ch Chi Ti·∫øt C√°c Y·∫øu T·ªë:")
                for i, factor in enumerate(insights['important_factors'], 1):
                    st.write(f"**{i}. {factor}**")
                    
                    factor_info = insights['factor_analysis'][factor]
                    
                    if factor_info['type'] == 'categorical':
                        # Y·∫øu t·ªë categorical
                        st.write(f"üèÜ **Lo·∫°i t·ªët nh·∫•t:** {factor_info['best_category']} ({factor_info['best_rate']:.1%} ƒë√°nh gi√° t·ªët)")
                        st.write("üìä **Chi ti·∫øt theo t·ª´ng lo·∫°i:**")
                        
                        details = factor_info['details']
                        if details:  # Ki·ªÉm tra n·∫øu c√≥ d·ªØ li·ªáu
                            for category, stats in details.items():
                                if isinstance(stats, dict) and 'Total_Reviews' in stats:
                                    total = stats['Total_Reviews']
                                    rate = stats['High_Rating_Rate']
                                    st.write(f"‚Ä¢ **{category}**: {total} ƒë√°nh gi√°, {rate:.1%} t·ªët")
                                else:
                                    st.write(f"‚Ä¢ **{category}**: D·ªØ li·ªáu kh√¥ng h·ª£p l·ªá")
                        else:
                            st.write("‚Ä¢ Kh√¥ng c√≥ d·ªØ li·ªáu chi ti·∫øt")
                            
                    else:
                        # Y·∫øu t·ªë numerical
                        st.write("üìä **So s√°nh gi√° tr·ªã trung b√¨nh:**")
                        st.write(f"‚Ä¢ ƒê√°nh gi√° t·ªët (‚â•4.0): **{factor_info['high_rating_avg']}**")
                        st.write(f"‚Ä¢ ƒê√°nh gi√° th·∫•p (<4.0): **{factor_info['low_rating_avg']}**")
                        st.write(f"‚Ä¢ Ch√™nh l·ªách: **{factor_info['difference']}** ({factor_info['impact']})")
                    
                    st.write("---")
                
                # Khuy·∫øn ngh·ªã c·ª• th·ªÉ
                st.subheader("üí° Khuy·∫øn Ngh·ªã C·ª• Th·ªÉ:")
                for recommendation in insights['recommendations']:
                    st.write(f"‚Ä¢ {recommendation}")
        else:
            st.error("D·ªØ li·ªáu kh√¥ng c√≥ c·ªôt 'Review Rating'")

    else:
        st.info("Ch·ªçn thu·∫≠t to√°n ·ªü sidebar ƒë·ªÉ ch·∫°y.")


if __name__ == "__main__":
    main()


