import streamlit as st
import pandas as pd
from src.utils import load_csv
from src.kmeans import run_kmeans, plot_clusters, plot_elbow_method, plot_cluster_stats
from src.naive_bayes import run_nb
from src.decision_tree_cart import run_dt_cart
from src.decision_tree_id3 import run_dt_id3
from src.decision_tree_quinlan import run_dt_quinlan
from src.apriori import run_apriori
from src.roughset import reduce_attributes


st.set_page_config(page_title="·ª®ng D·ª•ng Khai Th√°c D·ªØ Li·ªáu Trong Lƒ©nh V·ª±c B√°n H√†ng", layout="wide")


@st.cache_data
def load_fashion_retail_data() -> pd.DataFrame:
    try:
        return load_csv("data/datasets/Fashion_Retail_Sales.csv")
    except Exception:
        return pd.DataFrame()

def sidebar_controls():
    st.sidebar.header("Ch·ªçn thu·∫≠t to√°n")
    algo = st.sidebar.selectbox(
        "Thu·∫≠t to√°n",
        [
            "Apriori",
            "K-means", 
            "Naive Bayes",
            "Decision-Tree-CART",
            "Decision-Tree-ID3",
            "Decision-Tree-Quinlan",
            "Rough Set",
        ],
    )

    st.sidebar.header("D·ªØ li·ªáu")
    data_choice = st.sidebar.radio("Ngu·ªìn d·ªØ li·ªáu", ["M·∫∑c ƒë·ªãnh", "T·∫£i CSV"])
    uploaded = None
    if data_choice == "T·∫£i CSV":
        uploaded = st.sidebar.file_uploader("Ch·ªçn file CSV", type=["csv"]) 

    return algo, uploaded


def main():
    st.title("·ª®ng D·ª•ng Khai Th√°c D·ªØ Li·ªáu Trong Lƒ©nh V·ª±c B√°n H√†ng")
    st.write("Ch·ªçn thu·∫≠t to√°n v√† tham s·ªë ·ªü sidebar. K·∫øt qu·∫£ hi·ªÉn th·ªã ·ªü ƒë√¢y.")

    algo, uploaded = sidebar_controls()

    # Load data theo thu·∫≠t to√°n
    data_df = pd.DataFrame()
    if uploaded is not None:
        data_df = pd.read_csv(uploaded)
    else:
        data_df = load_fashion_retail_data()
    
    if data_df.empty:
        st.warning("Kh√¥ng t√¨m th·∫•y d·ªØ li·ªáu Fashion Retail Sales. H√£y t·∫£i CSV ho·∫∑c th√™m v√†o data/datasets/Fashion_Retail_Sales.csv")
        return

    st.subheader("D·ªØ li·ªáu s·ª≠ d·ª•ng")
    with st.expander("D·ªØ li·ªáu Fashion Retail Sales", expanded=False):
        st.dataframe(data_df)

    # Hi·ªÉn th·ªã d·ªØ li·ªáu ƒë·∫ßu v√†o cho thu·∫≠t to√°n ƒë∆∞·ª£c ch·ªçn
    if algo == "K-means":
        st.subheader("Thu·∫≠t to√°n ph√¢n c·ª•m K-means")
        st.write("**B√†i to√°n:** Ph√¢n nh√≥m kh√°ch h√†ng theo m·ª©c chi ti√™u v√† ƒë·ªô h√†i l√≤ng")
        st.write("**M·ª•c ti√™u:** Ph√¢n nh√≥m kh√°ch h√†ng d·ª±a tr√™n s·ªë ti·ªÅn chi ti√™u v√† m·ª©c ƒë·ªô h√†i l√≤ng, gi√∫p doanh nghi·ªáp nh·∫≠n di·ªán c√°c ph√¢n kh√∫c kh√°ch h√†ng ti·ªÅm nƒÉng ƒë·ªÉ t·ªëi ∆∞u h√≥a chi·∫øn l∆∞·ª£c marketing v√† chƒÉm s√≥c kh√°ch h√†ng.")
        # Chu·∫©n b·ªã d·ªØ li·ªáu cho K-means ph√¢n nh√≥m kh√°ch h√†ng
        if 'Purchase Amount (USD)' in data_df.columns and 'Review Rating' in data_df.columns:
            # X·ª≠ l√Ω missing values
            kmeans_data = data_df.dropna(subset=['Purchase Amount (USD)', 'Review Rating']).copy()
            
            st.write("**D·ªØ li·ªáu ƒë·∫ßu v√†o:**")
            kmeans_input = kmeans_data[['Customer Reference ID', 'Purchase Amount (USD)', 'Review Rating']].copy()
            st.dataframe(kmeans_input)
        else:
            st.error("D·ªØ li·ªáu kh√¥ng c√≥ c·ªôt 'Purchase Amount (USD)' ho·∫∑c 'Review Rating'")

    # Ph·∫ßn ch·∫°y thu·∫≠t to√°n K-means
    if algo == "K-means":
        
        # Chu·∫©n b·ªã d·ªØ li·ªáu cho K-means ph√¢n nh√≥m kh√°ch h√†ng
        if 'Purchase Amount (USD)' in data_df.columns and 'Review Rating' in data_df.columns:
            # X·ª≠ l√Ω missing values
            kmeans_data = data_df.dropna(subset=['Purchase Amount (USD)', 'Review Rating']).copy()
            
            k = st.slider("S·ªë nh√≥m kh√°ch h√†ng (k)", 2, 6, 4, help="S·ªë nh√≥m kh√°ch h√†ng mu·ªën ph√¢n chia")

            if st.button("Ch·∫°y K-means"):
                # Ch·∫°y K-means v·ªõi d·ªØ li·ªáu ƒë√£ chu·∫©n b·ªã
                labels, inertia, cluster_info = run_kmeans(kmeans_data, k=k)
                
                st.success(f"‚úÖ ƒê√£ ph√¢n nh√≥m {len(kmeans_data)} kh√°ch h√†ng th√†nh {k} nh√≥m (Inertia: {inertia:.2f})")

                # Bi·ªÉu ƒë·ªì elbow method
                st.subheader("S·ªë Nh√≥m Kh√°ch H√†ng T·ªëi ∆Øu (Theo ph∆∞∆°ng ph√°p Elbow)")
                fig_elbow = plot_elbow_method(kmeans_data, max_k=8, highlight_k=k)
                st.pyplot(fig_elbow)
                
                # Hi·ªÉn th·ªã k·∫øt qu·∫£ ph√¢n c·ª•m
                result = kmeans_data.copy()
                result["cluster"] = labels
                
                # Hi·ªÉn th·ªã th√¥ng tin chi ti·∫øt v·ªÅ c√°c nh√≥m
                st.subheader("Th√¥ng Tin Chi Ti·∫øt C√°c Nh√≥m Kh√°ch H√†ng")
                for cluster_id in sorted(cluster_info.keys()):
                    info = cluster_info[cluster_id]
                    with st.expander(f"Nh√≥m {cluster_id}: {info['type']}", expanded=True):
                        col1, col2, col3, col4 = st.columns(4)
                        with col1:
                            st.metric("S·ªë l∆∞·ª£ng", f"{info['count']} kh√°ch h√†ng")
                        with col2:
                            st.metric("Chi ti√™u TB", f"${info['avg_amount']}")
                        with col3:
                            st.metric("ƒê√°nh gi√° TB", f"{info['avg_rating']}/5.0")
                        with col4:
                            st.metric("T·ª∑ l·ªá", f"{info['percentage']}%")
                

                # Bi·ªÉu ƒë·ªì ph√¢n c·ª•m
                fig_clusters = plot_clusters(kmeans_data, labels, k)
                st.pyplot(fig_clusters)



                
                # Bi·ªÉu ƒë·ªì th·ªëng k√™
                st.subheader("Th·ªëng K√™ Chi Ti·∫øt")
                fig_stats = plot_cluster_stats(kmeans_data, labels, cluster_info)
                st.pyplot(fig_stats)
                
                # Khuy·∫øn ngh·ªã kinh doanh d·∫°ng b·∫£ng
                st.subheader("Khuy·∫øn Ngh·ªã Chi·∫øn L∆∞·ª£c Cho T·ª´ng Nh√≥m Kh√°ch H√†ng")
                
                # T·∫°o DataFrame cho khuy·∫øn ngh·ªã
                strategy_data = []
                for cluster_id in sorted(cluster_info.keys()):
                    info = cluster_info[cluster_id]
                    
                    if "VIP" in info['type']:
                        xep_loai = "∆Øu ti√™n cao nh·∫•t"
                        chien_luoc = "D·ªãch v·ª• ƒë·∫∑c bi·ªát, s·∫£n ph·∫©m cao c·∫•p, ch∆∞∆°ng tr√¨nh VIP"
                    elif "Trung th√†nh" in info['type']:
                        xep_loai = "Kh√°ch h√†ng trung th√†nh"
                        chien_luoc = "Gi·ªØ ch√¢n, tƒÉng gi√° tr·ªã ƒë∆°n h√†ng, ch∆∞∆°ng tr√¨nh khuy·∫øn m√£i"
                    elif "ch∆∞a h√†i l√≤ng" in info['type']:
                        xep_loai = "C·∫ßn c·∫£i thi·ªán"
                        chien_luoc = "N√¢ng cao ch·∫•t l∆∞·ª£ng d·ªãch v·ª•, kh·∫£o s√°t feedback, ch∆∞∆°ng tr√¨nh khuy·∫øn m√£i"
                    else:
                        xep_loai = "C·∫ßn quan t√¢m"
                        chien_luoc = "TƒÉng engagement, c·∫£i thi·ªán tr·∫£i nghi·ªám, gi√° c·∫£ h·ª£p l√Ω"
                    
                    strategy_data.append({
                        'Nh√≥m': cluster_id,
                        'Lo·∫°i': info['type'],
                        'X·∫øp lo·∫°i': xep_loai,
                        'S·ªë l∆∞·ª£ng': f"{info['count']} kh√°ch h√†ng",
                        'Chi ti√™u TB': f"${info['avg_amount']}",
                        'ƒê√°nh gi√° TB': f"{info['avg_rating']}/5.0",
                        'Chi·∫øn l∆∞·ª£c ƒë·ªÅ xu·∫•t': chien_luoc
                    })
                
                strategy_df = pd.DataFrame(strategy_data)
                st.dataframe(strategy_df, use_container_width=True)
                
        else:
            st.error("D·ªØ li·ªáu kh√¥ng c√≥ c·ªôt 'Purchase Amount (USD)' ho·∫∑c 'Review Rating'")

    elif algo == "Naive Bayes":
        st.subheader("Thu·∫≠t to√°n Naive Bayes")
        st.write("**B√†i to√°n:** D·ª± ƒëo√°n kh√°ch h√†ng c√≥ kh·∫£ nƒÉng quay l·∫°i mua h√†ng hay kh√¥ng")
        st.write("**M·ª•c ti√™u:** X√¢y d·ª±ng m√¥ h√¨nh d·ª± ƒëo√°n kh√°ch h√†ng c√≥ kh·∫£ nƒÉng quay l·∫°i mua h√†ng hay kh√¥ng, gi√∫p doanh nghi·ªáp t·ªëi ∆∞u h√≥a chi·∫øn l∆∞·ª£c marketing v√† chƒÉm s√≥c kh√°ch h√†ng.")
        
        if 'Review Rating' in data_df.columns and 'Item Purchased' in data_df.columns:
            # Chu·∫©n b·ªã d·ªØ li·ªáu cho Naive Bayes
            nb_data = data_df.copy()
            # Lo·∫°i b·ªè missing values
            nb_data = nb_data.dropna(subset=['Review Rating', 'Purchase Amount (USD)'])
            
            # Hi·ªÉn th·ªã d·ªØ li·ªáu ƒë·∫ßu v√†o
            st.write("**D·ªØ li·ªáu ƒë·∫ßu v√†o:**")
            if 'Will_Return' in nb_data.columns:
                # S·ª≠ d·ª•ng c·ªôt c√≥ s·∫µn
                nb_input = nb_data[['Review Rating', 'Purchase Amount (USD)', 'Item Purchased', 'Payment Method', 'Will_Return']].copy()
                st.dataframe(nb_input)
            else:
                # T·∫°o target m·ªõi (fallback)
                avg_amount = nb_data['Purchase Amount (USD)'].mean()
                nb_data['Will_Return'] = (
                    (nb_data['Review Rating'] >= 4.0) & 
                    (nb_data['Purchase Amount (USD)'] >= avg_amount * 0.8)
                ).astype(int)
                
                nb_input = nb_data[['Review Rating', 'Purchase Amount (USD)', 'Item Purchased', 'Payment Method', 'Will_Return']].copy()
                st.dataframe(nb_input.head(20))
                
                # Hi·ªÉn th·ªã th√¥ng tin v·ªÅ target
                will_return_count = nb_data['Will_Return'].sum()
                total_count = len(nb_data)
                st.info(f"**Ng∆∞·ª°ng d·ª± ƒëo√°n:** Rating ‚â• 4.0 v√† chi ti√™u ‚â• ${avg_amount*0.8:.0f} ({will_return_count}/{total_count} kh√°ch h√†ng)")
            
            if st.button("Ch·∫°y Naive Bayes"):
                metrics, y_pred = run_nb(nb_data, test_size=0.2)
                
                st.success(f"‚úÖ Ho√†n th√†nh d·ª± ƒëo√°n")
                
                # Hi·ªÉn th·ªã k·∫øt qu·∫£ d·ª± ƒëo√°n ƒë∆°n gi·∫£n
                st.subheader("K·∫øt Qu·∫£ D·ª± ƒêo√°n")
                
                prob_table = metrics['probability_table']
                
                # Hi·ªÉn th·ªã x√°c su·∫•t t·ªïng quan
                col1, col2 = st.columns(2)
                with col1:
                    will_return_prob = prob_table['prior_probabilities'].get(1, 0)
                    st.metric("Kh√°ch h√†ng s·∫Ω mua l·∫°i", f"{will_return_prob:.1%}")
                
                with col2:
                    no_return_prob = prob_table['prior_probabilities'].get(0, 0)
                    st.metric("Kh√°ch h√†ng kh√¥ng mua l·∫°i", f"{no_return_prob:.1%}")
                
                # Ph√¢n t√≠ch chi ti·∫øt theo nh√≥m
                st.subheader("Ph√¢n T√≠ch Chi Ti·∫øt Theo Nh√≥m")
                
                from src.naive_bayes import create_customer_insights, generate_business_recommendations
                insights = create_customer_insights(nb_data, prob_table)
                
                # Ph√¢n t√≠ch theo s·∫£n ph·∫©m
                st.write("**Ph√¢n t√≠ch theo s·∫£n ph·∫©m:**")
                product_df = insights['product_analysis'].reset_index()
                product_df.columns = ['S·∫£n ph·∫©m', 'T·ªïng s·ªë', 'S·∫Ω mua l·∫°i', 'T·ª∑ l·ªá mua l·∫°i']
                product_df['T·ª∑ l·ªá mua l·∫°i'] = product_df['T·ª∑ l·ªá mua l·∫°i'].apply(lambda x: f"{x:.1%}")
                st.dataframe(product_df, use_container_width=True)
                
                # Ph√¢n t√≠ch theo ph∆∞∆°ng th·ª©c thanh to√°n
                st.write("**Ph√¢n t√≠ch theo ph∆∞∆°ng th·ª©c thanh to√°n:**")
                payment_df = insights['payment_analysis'].reset_index()
                payment_df.columns = ['Ph∆∞∆°ng th·ª©c', 'T·ªïng s·ªë', 'S·∫Ω mua l·∫°i', 'T·ª∑ l·ªá mua l·∫°i']
                payment_df['T·ª∑ l·ªá mua l·∫°i'] = payment_df['T·ª∑ l·ªá mua l·∫°i'].apply(lambda x: f"{x:.1%}")
                st.dataframe(payment_df, use_container_width=True)
                
                # Ph√¢n t√≠ch theo m·ª©c chi ti√™u
                st.write("**Ph√¢n t√≠ch theo m·ª©c chi ti√™u:**")
                spending_df = insights['spending_analysis'].reset_index()
                spending_df.columns = ['M·ª©c chi ti√™u', 'T·ªïng s·ªë', 'S·∫Ω mua l·∫°i', 'T·ª∑ l·ªá mua l·∫°i']
                spending_df['T·ª∑ l·ªá mua l·∫°i'] = spending_df['T·ª∑ l·ªá mua l·∫°i'].apply(lambda x: f"{x:.1%}")
                st.dataframe(spending_df, use_container_width=True)
                
                # Khuy·∫øn ngh·ªã kinh doanh
                st.subheader("T·ªïng K·∫øt ƒê·ªÅ Xu·∫•t")
                recommendations = generate_business_recommendations(insights)
                
                for rec in recommendations:
                    st.write(rec)
        else:
            st.error("D·ªØ li·ªáu kh√¥ng c√≥ c·ªôt 'Review Rating' ho·∫∑c 'Item Purchased'")

    elif algo == "Decision-Tree-CART":
        st.subheader("Thu·∫≠t to√°n c√¢y quy·∫øt ƒë·ªãnh - Decision Tree CART")
        st.write("**B√†i to√°n:** Quy·∫øt ƒë·ªãnh s·∫£n ph·∫©m n√™n nh·∫≠p/n√™n d·ª´ng")
        st.write("**Thu·∫≠t to√°n CART:** S·ª≠ d·ª•ng Gini ƒë·ªÉ x√¢y d·ª±ng c√¢y quy·∫øt ƒë·ªãnh")
        st.write("**Y·∫øu t·ªë ·∫£nh h∆∞·ªüng:** Sales_Volume, Profit_Margin, Customer_Demand, Seasonality")
        st.write("**M·ª•c ti√™u:** Restock (Yes/No) - d·ª±a tr√™n Sales cao, Rating t·ªët, Gi√° tr·ªã h·ª£p l√Ω")
        
        if 'Review Rating' in data_df.columns and 'Item Purchased' in data_df.columns and 'Purchase Amount (USD)' in data_df.columns:
            # Hi·ªÉn th·ªã d·ªØ li·ªáu ƒë·∫ßu v√†o
            st.write("**D·ªØ li·ªáu ƒë·∫ßu v√†o:**")
            st.dataframe(data_df[['Item Purchased', 'Purchase Amount (USD)', 'Payment Method', 'Review Rating', 'Date Purchase']].head(20))
            
            if st.button("Ch·∫°y CART"):
                metrics = run_dt_cart(data_df)
                
                st.success("‚úÖ Ho√†n th√†nh ph√¢n t√≠ch Decision Tree CART")
                
                # Hi·ªÉn th·ªã th·ªëng k√™ t·ªïng quan
                data_summary = metrics['data_summary']
                st.subheader("1. Th·ªëng K√™ T·ªïng Quan")
                col1, col2, col3, col4 = st.columns(4)
                with col1:
                    st.metric("T·ªïng m·∫´u", data_summary['total_samples'])
                with col2:
                    st.metric("N√™n nh·∫≠p", f"{data_summary['should_restock_count']} ({data_summary['should_restock_count']/data_summary['total_samples']:.1%})")
                with col3:
                    st.metric("N√™n d·ª´ng", f"{data_summary['should_stop_count']} ({data_summary['should_stop_count']/data_summary['total_samples']:.1%})")
                with col4:
                    st.metric("Accuracy", f"{metrics['accuracy']:.1%}")
                
                # Hi·ªÉn th·ªã b·∫£ng Gini Impurity v√† Information Gain
                gini_info = metrics['gini_info']
                st.subheader("2. B·∫£ng Gini Impurity v√† Information Gain")
                gain_data = []
                for feature, gain_info in gini_info['feature_gains'].items():
                    gain_data.append({
                        'Thu·ªôc t√≠nh': feature,
                        'Information Gain': f"{gain_info['information_gain']:.3f}",
                        'Weighted Gini': f"{gain_info['weighted_gini']:.3f}"
                    })
                
                gain_df = pd.DataFrame(gain_data)
                st.dataframe(gain_df, use_container_width=True)
                
                # Hi·ªÉn th·ªã chi ti·∫øt Gini
                st.subheader("3. Chi Ti·∫øt Gini Impurity Theo Thu·ªôc T√≠nh")
                
                for feature, gain_info in gini_info['feature_gains'].items():
                    with st.expander(f"üìä {feature} (Gain: {gain_info['information_gain']:.3f})"):
                        st.write("**Ph√¢n b·ªë thu·ªôc t√≠nh:**")
                        feature_dist = gain_info['feature_distribution']
                        for value, count in feature_dist.items():
                            st.write(f"‚Ä¢ {value}: {count} m·∫´u")
                        
                        st.write("**Chi ti·∫øt Gini Impurity:**")
                        gini_details = gain_info['gini_details']
                        for value, details in gini_details.items():
                            st.write(f"**{value}:**")
                            st.write(f"  - S·ªë m·∫´u: {details['count']}")
                            st.write(f"  - Gini: {details['gini']:.3f}")
                            st.write(f"  - Ph√¢n b·ªë: {details['target_distribution']}")
                
                # Hi·ªÉn th·ªã s∆° ƒë·ªì c√¢y quy·∫øt ƒë·ªãnh tr·ª±c quan
                st.subheader("4. S∆° ƒê·ªì C√¢y Quy·∫øt ƒê·ªãnh")
                
                tree_figure = metrics.get('decision_tree_figure')
                if tree_figure is not None:
                    st.write("**S∆° ƒë·ªì c√¢y quy·∫øt ƒë·ªãnh tr·ª±c quan:**")
                    st.pyplot(tree_figure)
                else:
                    st.write("**S∆° ƒë·ªì tr·ª±c quan kh√¥ng kh·∫£ d·ª•ng, hi·ªÉn th·ªã d·∫°ng text:**")
                    tree_rules = metrics['decision_tree_rules']
                    st.text_area("C√¢y quy·∫øt ƒë·ªãnh CART:", tree_rules, height=200)
                
                # Ph√¢n t√≠ch k·∫øt qu·∫£
                st.subheader("5. Ph√¢n T√≠ch K·∫øt Qu·∫£")
                restock_analysis = metrics['restock_analysis']
                
                # Ph√¢n t√≠ch theo Sales_Volume
                st.write("**Ph√¢n t√≠ch theo kh·ªëi l∆∞·ª£ng b√°n:**")
                sales_data = []
                for sales_volume, stats in restock_analysis['Sales_Volume'].items():
                    sales_data.append({
                        'Kh·ªëi l∆∞·ª£ng b√°n': sales_volume,
                        'S·ªë m·∫´u': stats['count'],
                        'N√™n nh·∫≠p': stats['should_restock'],
                        'T·ª∑ l·ªá n√™n nh·∫≠p': f"{stats['restock_rate']}%"
                    })
                
                sales_df = pd.DataFrame(sales_data)
                st.dataframe(sales_df, use_container_width=True)
                
                # Ph√¢n t√≠ch theo Profit_Margin
                st.write("**Ph√¢n t√≠ch theo t·ª∑ su·∫•t l·ª£i nhu·∫≠n:**")
                profit_data = []
                for profit_margin, stats in restock_analysis['Profit_Margin'].items():
                    profit_data.append({
                        'T·ª∑ su·∫•t l·ª£i nhu·∫≠n': profit_margin,
                        'S·ªë m·∫´u': stats['count'],
                        'N√™n nh·∫≠p': stats['should_restock'],
                        'T·ª∑ l·ªá n√™n nh·∫≠p': f"{stats['restock_rate']}%"
                    })
                
                profit_df = pd.DataFrame(profit_data)
                st.dataframe(profit_df, use_container_width=True)
                
                # Ph√¢n t√≠ch theo Customer_Demand
                st.write("**Ph√¢n t√≠ch theo m·ª©c ƒë·ªô quan t√¢m kh√°ch h√†ng:**")
                demand_data = []
                for customer_demand, stats in restock_analysis['Customer_Demand'].items():
                    demand_data.append({
                        'M·ª©c ƒë·ªô quan t√¢m': customer_demand,
                        'S·ªë m·∫´u': stats['count'],
                        'N√™n nh·∫≠p': stats['should_restock'],
                        'T·ª∑ l·ªá n√™n nh·∫≠p': f"{stats['restock_rate']}%"
                    })
                
                demand_df = pd.DataFrame(demand_data)
                st.dataframe(demand_df, use_container_width=True)
                
                # Ph√¢n t√≠ch theo Seasonality
                st.write("**Ph√¢n t√≠ch theo t√≠nh m√πa v·ª•:**")
                season_data = []
                for seasonality, stats in restock_analysis['Seasonality'].items():
                    season_data.append({
                        'M√πa v·ª•': seasonality,
                        'S·ªë m·∫´u': stats['count'],
                        'N√™n nh·∫≠p': stats['should_restock'],
                        'T·ª∑ l·ªá n√™n nh·∫≠p': f"{stats['restock_rate']}%"
                    })
                
                season_df = pd.DataFrame(season_data)
                st.dataframe(season_df, use_container_width=True)
                
                # K·∫øt lu·∫≠n
                st.subheader("6. K·∫øt Lu·∫≠n")
                best_feature = list(gini_info['feature_gains'].keys())[0]
                best_gain = gini_info['feature_gains'][best_feature]['information_gain']
                
                st.write(f"**Thu·ªôc t√≠nh quan tr·ªçng nh·∫•t**: {best_feature} (Gain: {best_gain:.3f})")
                overview = restock_analysis['overview']
                if overview['restock_rate'] > 50:
                    st.write("T·ª∑ l·ªá s·∫£n ph·∫©m n√™n nh·∫≠p cao - t·∫≠p trung m·ªü r·ªông inventory")
                else:
                    st.write("T·ª∑ l·ªá s·∫£n ph·∫©m n√™n nh·∫≠p th·∫•p - c·∫ßn c·∫£i thi·ªán ch·∫•t l∆∞·ª£ng s·∫£n ph·∫©m")
                
        else:
            st.error("D·ªØ li·ªáu kh√¥ng c√≥ ƒë·ªß c·ªôt c·∫ßn thi·∫øt: 'Review Rating', 'Item Purchased', 'Purchase Amount (USD)'")

    elif algo == "Decision-Tree-ID3":
        st.subheader("Thu·∫≠t to√°n c√¢y quy·∫øt ƒë·ªãnh - Decision Tree ID3")
        st.write("**B√†i to√°n:** D·ª± ƒëo√°n kh√°ch h√†ng c√≥ mua h√†ng hay kh√¥ng")
        st.write("**M·ª•c ti√™u:** D·ª± ƒëo√°n kh√°ch h√†ng c√≥ mua h√†ng hay kh√¥ng, gi√∫p doanh nghi·ªáp t·ªëi ∆∞u h√≥a chi·∫øn l∆∞·ª£c marketing v√† chƒÉm s√≥c kh√°ch h√†ng.")
        st.write("**Y·∫øu t·ªë ·∫£nh h∆∞·ªüng:** Item_Type, Price_Range, Payment_Preference, Customer_Type")
        st.write("**M·ª•c ti√™u:** Will_Buy (Yes/No) - d·ª±a tr√™n Review Rating ‚â• 3.5 v√† gi√° tr·ªã ‚â• $100")
        
        if 'Review Rating' in data_df.columns and 'Item Purchased' in data_df.columns and 'Purchase Amount (USD)' in data_df.columns:
            # Hi·ªÉn th·ªã d·ªØ li·ªáu ƒë·∫ßu v√†o
            st.write("**D·ªØ li·ªáu ƒë·∫ßu v√†o:**")
            st.dataframe(data_df[['Item Purchased', 'Purchase Amount (USD)', 'Payment Method', 'Review Rating', 'Will_Return']].head(20))
            
            if st.button("Ch·∫°y ID3"):
                metrics = run_dt_id3(data_df)
                
                st.success("‚úÖ Ho√†n th√†nh ph√¢n t√≠ch Decision Tree ID3")
                
                # Hi·ªÉn th·ªã th·ªëng k√™ t·ªïng quan
                data_summary = metrics['data_summary']
                st.subheader("1. Th·ªëng K√™ T·ªïng Quan")
                col1, col2, col3, col4 = st.columns(4)
                with col1:
                    st.metric("T·ªïng m·∫´u", data_summary['total_samples'])
                with col2:
                    st.metric("S·∫Ω mua", f"{data_summary['will_buy_count']} ({data_summary['will_buy_count']/data_summary['total_samples']:.1%})")
                with col3:
                    st.metric("Kh√¥ng mua", f"{data_summary['will_not_buy_count']} ({data_summary['will_not_buy_count']/data_summary['total_samples']:.1%})")
                with col4:
                    st.metric("Accuracy", f"{metrics['accuracy']:.1%}")
                
                # Hi·ªÉn th·ªã b·∫£ng Information Gain
                entropy_info = metrics['entropy_info']
                st.subheader("2. B·∫£ng Information Gain")
                gain_data = []
                for feature, gain_info in entropy_info['feature_gains'].items():
                    gain_data.append({
                        'Thu·ªôc t√≠nh': feature,
                        'Information Gain': f"{gain_info['information_gain']:.3f}",
                        'Weighted Entropy': f"{gain_info['weighted_entropy']:.3f}"
                    })
                
                gain_df = pd.DataFrame(gain_data)
                st.dataframe(gain_df, use_container_width=True)
                
                # Hi·ªÉn th·ªã chi ti·∫øt Entropy
                st.subheader("3. Chi Ti·∫øt Entropy Theo Thu·ªôc T√≠nh")
                
                for feature, gain_info in entropy_info['feature_gains'].items():
                    with st.expander(f"üìä {feature} (Gain: {gain_info['information_gain']:.3f})"):
                        st.write("**Ph√¢n b·ªë thu·ªôc t√≠nh:**")
                        feature_dist = gain_info['feature_distribution']
                        for value, count in feature_dist.items():
                            st.write(f"‚Ä¢ {value}: {count} m·∫´u")
                        
                        st.write("**Chi ti·∫øt Entropy:**")
                        entropy_details = gain_info['entropy_details']
                        for value, details in entropy_details.items():
                            st.write(f"**{value}:**")
                            st.write(f"  - S·ªë m·∫´u: {details['count']}")
                            st.write(f"  - Entropy: {details['entropy']:.3f}")
                            st.write(f"  - Ph√¢n b·ªë: {details['target_distribution']}")
                
                # Hi·ªÉn th·ªã s∆° ƒë·ªì c√¢y quy·∫øt ƒë·ªãnh tr·ª±c quan
                st.subheader("4. S∆° ƒê·ªì C√¢y Quy·∫øt ƒê·ªãnh")
                
                tree_figure = metrics.get('decision_tree_figure')
                if tree_figure is not None:
                    st.write("**S∆° ƒë·ªì c√¢y quy·∫øt ƒë·ªãnh tr·ª±c quan:**")
                    st.pyplot(tree_figure)
                else:
                    st.write("**S∆° ƒë·ªì tr·ª±c quan kh√¥ng kh·∫£ d·ª•ng, hi·ªÉn th·ªã d·∫°ng text:**")
                    tree_rules = metrics['decision_tree_rules']
                    st.text_area("C√¢y quy·∫øt ƒë·ªãnh ID3:", tree_rules, height=200)
                
                # Ph√¢n t√≠ch k·∫øt qu·∫£
                st.subheader("5. Ph√¢n T√≠ch K·∫øt Qu·∫£")
                purchase_analysis = metrics['purchase_analysis']
                
                # Ph√¢n t√≠ch theo Item_Type
                st.write("**Ph√¢n t√≠ch theo lo·∫°i s·∫£n ph·∫©m:**")
                item_type_data = []
                for item_type, stats in purchase_analysis['Item_Type'].items():
                    item_type_data.append({
                        'Lo·∫°i s·∫£n ph·∫©m': item_type,
                        'S·ªë m·∫´u': stats['count'],
                        'S·∫Ω mua': stats['will_buy'],
                        'T·ª∑ l·ªá mua': f"{stats['buy_rate']}%"
                    })
                
                item_type_df = pd.DataFrame(item_type_data)
                st.dataframe(item_type_df, use_container_width=True)
                
                # Ph√¢n t√≠ch theo Price_Range
                st.write("**Ph√¢n t√≠ch theo m·ª©c gi√°:**")
                price_data = []
                for price_range, stats in purchase_analysis['Price_Range'].items():
                    price_data.append({
                        'M·ª©c gi√°': price_range,
                        'S·ªë m·∫´u': stats['count'],
                        'S·∫Ω mua': stats['will_buy'],
                        'T·ª∑ l·ªá mua': f"{stats['buy_rate']}%"
                    })
                
                price_df = pd.DataFrame(price_data)
                st.dataframe(price_df, use_container_width=True)
                
                # Ph√¢n t√≠ch theo Customer_Type
                st.write("**Ph√¢n t√≠ch theo lo·∫°i kh√°ch h√†ng:**")
                customer_data = []
                for customer_type, stats in purchase_analysis['Customer_Type'].items():
                    customer_data.append({
                        'Lo·∫°i kh√°ch h√†ng': customer_type,
                        'S·ªë m·∫´u': stats['count'],
                        'S·∫Ω mua': stats['will_buy'],
                        'T·ª∑ l·ªá mua': f"{stats['buy_rate']}%"
                    })
                
                customer_df = pd.DataFrame(customer_data)
                st.dataframe(customer_df, use_container_width=True)
                
                # K·∫øt lu·∫≠n
                st.subheader("6. K·∫øt Lu·∫≠n")
                best_feature = list(entropy_info['feature_gains'].keys())[0]
                best_gain = entropy_info['feature_gains'][best_feature]['information_gain']
                
                st.write(f"**Thu·ªôc t√≠nh quan tr·ªçng nh·∫•t**: {best_feature} (Gain: {best_gain:.3f})")
                st.write("**M·ª•c ƒë√≠ch**: D·ª± ƒëo√°n kh·∫£ nƒÉng mua h√†ng c·ªßa kh√°ch h√†ng")
                st.write("**·ª®ng d·ª•ng**: T·ªëi ∆∞u h√≥a marketing, c√° nh√¢n h√≥a tr·∫£i nghi·ªám kh√°ch h√†ng")
                
                # Khuy·∫øn ngh·ªã
                st.write("**Khuy·∫øn ngh·ªã:**")
                overview = purchase_analysis['overview']
                if overview['buy_rate'] > 50:
                    st.write("‚Ä¢ T·ª∑ l·ªá mua h√†ng cao - t·∫≠p trung duy tr√¨ ch·∫•t l∆∞·ª£ng d·ªãch v·ª•")
                else:
                    st.write("‚Ä¢ T·ª∑ l·ªá mua h√†ng th·∫•p - c·∫ßn c·∫£i thi·ªán tr·∫£i nghi·ªám kh√°ch h√†ng")
                
                st.write(f"‚Ä¢ T·ªïng c·ªông {overview['total_samples']} m·∫´u, {overview['will_buy']} kh√°ch h√†ng c√≥ kh·∫£ nƒÉng mua ({overview['buy_rate']}%)")
        else:
            st.error("D·ªØ li·ªáu kh√¥ng c√≥ ƒë·ªß c·ªôt c·∫ßn thi·∫øt: 'Review Rating', 'Item Purchased', 'Purchase Amount (USD)'")

    elif algo == "Decision-Tree-Quinlan":
        st.subheader("Thu·∫≠t to√°n c√¢y quy·∫øt ƒë·ªãnh - Decision Tree Quinlan (C4.5)")
        st.write("**B√†i to√°n:** D·ª± ƒëo√°n xu h∆∞·ªõng m√πa v·ª•")
        st.write("**M·ª•c ti√™u:** D·ª± ƒëo√°n xu h∆∞·ªõng m√πa v·ª•, gi√∫p doanh nghi·ªáp t·ªëi ∆∞u h√≥a chi·∫øn l∆∞·ª£c s·∫£n ph·∫©m v√† marketing m√πa v·ª•.")
        st.write("**Thu·∫≠t to√°n C4.5:** S·ª≠ d·ª•ng Gain Ratio ƒë·ªÉ x√¢y d·ª±ng c√¢y quy·∫øt ƒë·ªãnh")
        st.write("**Y·∫øu t·ªë ·∫£nh h∆∞·ªüng:** Product_Category, Price_Level, Customer_Segment, Time_Period")
        st.write("**Output:** Seasonal_Trend (High/Low) - d·ª±a tr√™n Rating t·ªët, Gi√° cao, Th·ªùi k·ª≥ ph√π h·ª£p")
        
        if 'Review Rating' in data_df.columns and 'Item Purchased' in data_df.columns and 'Purchase Amount (USD)' in data_df.columns:
            # Hi·ªÉn th·ªã d·ªØ li·ªáu ƒë·∫ßu v√†o
            st.write("**D·ªØ li·ªáu ƒë·∫ßu v√†o:**")
            st.dataframe(data_df[['Item Purchased', 'Purchase Amount (USD)', 'Payment Method', 'Review Rating', 'Date Purchase', 'Will_Return']].head(20))
            
            if st.button("Ch·∫°y Quinlan"):
                metrics = run_dt_quinlan(data_df)
                
                st.success("‚úÖ Ho√†n th√†nh ph√¢n t√≠ch Decision Tree Quinlan (C4.5)")
                
                # Hi·ªÉn th·ªã th·ªëng k√™ t·ªïng quan
                data_summary = metrics['data_summary']
                st.subheader("1. Th·ªëng K√™ T·ªïng Quan")
                col1, col2, col3, col4 = st.columns(4)
                with col1:
                    st.metric("T·ªïng m·∫´u", data_summary['total_samples'])
                with col2:
                    st.metric("Xu h∆∞·ªõng cao", f"{data_summary['high_trend_count']} ({data_summary['high_trend_count']/data_summary['total_samples']:.1%})")
                with col3:
                    st.metric("Xu h∆∞·ªõng th·∫•p", f"{data_summary['low_trend_count']} ({data_summary['low_trend_count']/data_summary['total_samples']:.1%})")
                with col4:
                    st.metric("Accuracy", f"{metrics['accuracy']:.1%}")
                
                # Hi·ªÉn th·ªã b·∫£ng Gain Ratio
                gain_ratio_info = metrics['gain_ratio_info']
                st.subheader("2. B·∫£ng Entropy v√† Gain Ratio")
                gain_data = []
                for feature, gain_info in gain_ratio_info['feature_gains'].items():
                    gain_data.append({
                        'Thu·ªôc t√≠nh': feature,
                        'Information Gain': f"{gain_info['information_gain']:.3f}",
                        'Split Information': f"{gain_info['split_information']:.3f}",
                        'Gain Ratio': f"{gain_info['gain_ratio']:.3f}"
                    })
                
                gain_df = pd.DataFrame(gain_data)
                st.dataframe(gain_df, use_container_width=True)
                
                # Hi·ªÉn th·ªã chi ti·∫øt Gain Ratio
                st.subheader("3. Chi Ti·∫øt Gain Ratio Theo Thu·ªôc T√≠nh")
                
                for feature, gain_info in gain_ratio_info['feature_gains'].items():
                    with st.expander(f"üìä {feature} (Gain Ratio: {gain_info['gain_ratio']:.3f})"):
                        st.write("**Ph√¢n b·ªë thu·ªôc t√≠nh:**")
                        feature_dist = gain_info['feature_distribution']
                        for value, count in feature_dist.items():
                            st.write(f"‚Ä¢ {value}: {count} m·∫´u")
                        
                        st.write("**Chi ti·∫øt Entropy:**")
                        entropy_details = gain_info['entropy_details']
                        for value, details in entropy_details.items():
                            st.write(f"**{value}:**")
                            st.write(f"  - S·ªë m·∫´u: {details['count']}")
                            st.write(f"  - Entropy: {details['entropy']:.3f}")
                            st.write(f"  - Ph√¢n b·ªë: {details['target_distribution']}")
                
                # Hi·ªÉn th·ªã s∆° ƒë·ªì c√¢y quy·∫øt ƒë·ªãnh tr·ª±c quan
                st.subheader("4. S∆° ƒê·ªì C√¢y Quy·∫øt ƒê·ªãnh")
                
                tree_figure = metrics.get('decision_tree_figure')
                if tree_figure is not None:
                    st.write("**S∆° ƒë·ªì c√¢y quy·∫øt ƒë·ªãnh tr·ª±c quan:**")
                    st.pyplot(tree_figure)
                else:
                    st.write("**S∆° ƒë·ªì tr·ª±c quan kh√¥ng kh·∫£ d·ª•ng, hi·ªÉn th·ªã d·∫°ng text:**")
                    tree_rules = metrics['decision_tree_rules']
                    st.text_area("C√¢y quy·∫øt ƒë·ªãnh C4.5:", tree_rules, height=200)
                
                # Ph√¢n t√≠ch k·∫øt qu·∫£
                st.subheader("5. Ph√¢n T√≠ch K·∫øt Qu·∫£")
                seasonal_analysis = metrics['seasonal_analysis']
                
                # Ph√¢n t√≠ch theo Product_Category
                st.write("**Ph√¢n t√≠ch theo danh m·ª•c s·∫£n ph·∫©m:**")
                product_data = []
                for product_category, stats in seasonal_analysis['Product_Category'].items():
                    product_data.append({
                        'Danh m·ª•c s·∫£n ph·∫©m': product_category,
                        'S·ªë m·∫´u': stats['count'],
                        'Xu h∆∞·ªõng cao': stats['high_trend'],
                        'T·ª∑ l·ªá xu h∆∞·ªõng cao': f"{stats['high_trend_rate']}%"
                    })
                
                product_df = pd.DataFrame(product_data)
                st.dataframe(product_df, use_container_width=True)
                
                # Ph√¢n t√≠ch theo Price_Level
                st.write("**Ph√¢n t√≠ch theo m·ª©c gi√°:**")
                price_data = []
                for price_level, stats in seasonal_analysis['Price_Level'].items():
                    price_data.append({
                        'M·ª©c gi√°': price_level,
                        'S·ªë m·∫´u': stats['count'],
                        'Xu h∆∞·ªõng cao': stats['high_trend'],
                        'T·ª∑ l·ªá xu h∆∞·ªõng cao': f"{stats['high_trend_rate']}%"
                    })
                
                price_df = pd.DataFrame(price_data)
                st.dataframe(price_df, use_container_width=True)
                
                # Ph√¢n t√≠ch theo Customer_Segment
                st.write("**Ph√¢n t√≠ch theo ph√¢n kh√∫c kh√°ch h√†ng:**")
                segment_data = []
                for customer_segment, stats in seasonal_analysis['Customer_Segment'].items():
                    segment_data.append({
                        'Ph√¢n kh√∫c kh√°ch h√†ng': customer_segment,
                        'S·ªë m·∫´u': stats['count'],
                        'Xu h∆∞·ªõng cao': stats['high_trend'],
                        'T·ª∑ l·ªá xu h∆∞·ªõng cao': f"{stats['high_trend_rate']}%"
                    })
                
                segment_df = pd.DataFrame(segment_data)
                st.dataframe(segment_df, use_container_width=True)
                
                # Ph√¢n t√≠ch theo Time_Period
                st.write("**Ph√¢n t√≠ch theo th·ªùi k·ª≥:**")
                time_data = []
                for time_period, stats in seasonal_analysis['Time_Period'].items():
                    time_data.append({
                        'Th·ªùi k·ª≥': time_period,
                        'S·ªë m·∫´u': stats['count'],
                        'Xu h∆∞·ªõng cao': stats['high_trend'],
                        'T·ª∑ l·ªá xu h∆∞·ªõng cao': f"{stats['high_trend_rate']}%"
                    })
                
                time_df = pd.DataFrame(time_data)
                st.dataframe(time_df, use_container_width=True)
                
                # K·∫øt lu·∫≠n
                st.subheader("6. K·∫øt Lu·∫≠n")
                best_feature = list(gain_ratio_info['feature_gains'].keys())[0]
                best_gain_ratio = gain_ratio_info['feature_gains'][best_feature]['gain_ratio']
                
                st.write(f"**Thu·ªôc t√≠nh quan tr·ªçng nh·∫•t**: {best_feature} (Gain Ratio: {best_gain_ratio:.3f})")
                st.write("**M·ª•c ƒë√≠ch**: D·ª± ƒëo√°n xu h∆∞·ªõng m√πa v·ª• c·ªßa s·∫£n ph·∫©m")
                st.write("**·ª®ng d·ª•ng**: K·∫ø ho·∫°ch s·∫£n ph·∫©m theo m√πa, marketing m√πa v·ª•, t·ªëi ∆∞u h√≥a inventory")
                
                # Khuy·∫øn ngh·ªã
                overview = seasonal_analysis['overview']
                if overview['high_trend_rate'] > 50:
                    st.write("T·ª∑ l·ªá xu h∆∞·ªõng m√πa v·ª• cao - t·∫≠p trung ph√°t tri·ªÉn s·∫£n ph·∫©m theo m√πa")
                else:
                    st.write("T·ª∑ l·ªá xu h∆∞·ªõng m√πa v·ª• th·∫•p - c·∫ßn c·∫£i thi·ªán chi·∫øn l∆∞·ª£c m√πa v·ª•")
                
        else:
            st.error("D·ªØ li·ªáu kh√¥ng c√≥ ƒë·ªß c·ªôt c·∫ßn thi·∫øt: 'Review Rating', 'Item Purchased', 'Purchase Amount (USD)'")

    elif algo == "Apriori":
        st.subheader("Thu·∫≠t To√°n Apriori (T·∫≠p ph·ªï bi·∫øn v√† lu·∫≠t li√™n k·∫øt)")
        st.write("**B√†i to√°n:** ƒê∆∞a ra c√°c s·∫£n ph·∫©m kh√°c h√†ng th∆∞·ªùng ƒë∆∞·ª£c ch·ªçn k√®m m·ªói l·∫ßn mua s·∫Øm, t·ª´ ƒë√≥ gi√∫p ƒë∆∞a ra g·ª£i √Ω b·ªë tr√≠ s·∫£n ph·∫©m h·ª£p l√Ω ƒë·ªÉ tƒÉng hi·ªáu qu·∫£ b√°n h√†ng.")
        st.write("**M·ª•c ti√™u:** Thu·∫≠t to√°n Apriori ƒë∆∞·ª£c d√πng trong b√†i to√°n ƒë·ªÉ ƒë∆∞a ra c√°c s·∫£n ph·∫©m kh√°c h√†ng th∆∞·ªùng ƒë∆∞·ª£c ch·ªçn k√®m m·ªói l·∫ßn mua s·∫Øm, t·ª´ ƒë√≥ gi√∫p ƒë∆∞a ra g·ª£i √Ω b·ªë tr√≠ s·∫£n ph·∫©m h·ª£p l√Ω ƒë·ªÉ tƒÉng hi·ªáu qu·∫£ b√°n h√†ng.")
        
        # Hi·ªÉn th·ªã d·ªØ li·ªáu ƒë·∫ßu v√†o cho Apriori
        if 'Customer Reference ID' in data_df.columns and 'Item Purchased' in data_df.columns:
            # T·∫°o transactions theo customer - m·ªói customer c√≥ nhi·ªÅu items
            transactions_df = data_df[['Customer Reference ID', 'Item Purchased']].copy()
            
            st.write("**D·ªØ li·ªáu ƒë·∫ßu v√†o:**")
            st.dataframe(transactions_df)
        else:
            st.error("D·ªØ li·ªáu kh√¥ng c√≥ c·ªôt 'Customer Reference ID' ho·∫∑c 'Item Purchased'")
        
        min_sup = st.slider("Min support", 0.01, 0.2, 0.05, help="t·∫ßn s·ªë trong bao nhi√™u ph·∫ßn trƒÉm d·ªØ li·ªáu th√¨ nh·ªØng ƒëi·ªÅu ·ªü v·∫ø tr√°i v√† v·∫ø ph·∫£i c√πng x·∫£y ra")
        min_conf = st.slider("Min confidence", 0.2, 0.8, 0.4, help="ƒë·ªô m·∫°nh n·∫øu v·∫ø tr√°i x·∫£y ra th√¨ c√≥ bao nhi√™u kh·∫£ nƒÉng v·∫ø ph·∫£i x·∫£y ra")
        top_k = st.slider("S·ªë lu·∫≠t t·ªët nh·∫•t (top-k)", 3, 15, 5, help="S·ªë lu·∫≠t t·ªët nh·∫•t hi·ªÉn th·ªã")

        if st.button("Ch·∫°y Apriori"):
            # Chu·∫©n b·ªã d·ªØ li·ªáu cho Apriori: gom theo Customer ID
            if 'Customer Reference ID' in data_df.columns and 'Item Purchased' in data_df.columns:
                st.info(f"**ƒêang ph√¢n t√≠ch:** {len(transactions_df)} giao d·ªãch t·ª´ {transactions_df['Customer Reference ID'].nunique()} kh√°ch h√†ng")
                
                # T·∫°o transactions list
                transactions_list = transactions_df.groupby('Customer Reference ID')['Item Purchased'].apply(list).tolist()
                transactions_list = [items for items in transactions_list if items]  # Lo·∫°i b·ªè empty
                
                # T·∫°o One-Hot Matrix ƒë·ªÉ hi·ªÉn th·ªã
                st.write("**Ma tr·∫≠n bi·ªÉu di·ªÖn t·∫≠p giao d·ªãch:**")
                try:
                    from mlxtend.preprocessing import TransactionEncoder
                    
                    if transactions_list:
                        te = TransactionEncoder()
                        arr = te.fit_transform(transactions_list)
                        ohe_df = pd.DataFrame(arr, columns=te.columns_)
                        ohe_df.index = [f"Customer_{i+1}" for i in range(len(ohe_df))]
                        
                        # Ch·ªâ hi·ªÉn th·ªã m·ªôt ph·∫ßn ƒë·ªÉ kh√¥ng qu√° d√†i
                        display_cols = min(10, len(ohe_df.columns))
                        st.dataframe(ohe_df.iloc[:15, :display_cols])
                        
                        if len(ohe_df.columns) > display_cols:
                            st.info(f"Hi·ªÉn th·ªã {display_cols}/{len(ohe_df.columns)} c·ªôt. T·ªïng c·ªông c√≥ {len(ohe_df)} transactions v√† {len(ohe_df.columns)} s·∫£n ph·∫©m.")
                    else:
                        st.warning("Kh√¥ng c√≥ d·ªØ li·ªáu ƒë·ªÉ t·∫°o ma tr·∫≠n")
                except Exception as e:
                    st.error(f"L·ªói t·∫°o One-Hot Matrix: {str(e)}")
                
                # Ch·∫°y thu·∫≠t to√°n Apriori               
                frequent, rules = run_apriori(transactions_df, min_support=min_sup, min_confidence=min_conf, top_k=top_k)
                
                # Hi·ªÉn th·ªã k·∫øt qu·∫£
                st.write("**T·∫≠p ph·ªï bi·∫øn th·ªèa min-support:**", min_sup)
                if not frequent.empty:
                    st.dataframe(frequent.head(20))
                    st.write(f"T√¨m th·∫•y {len(frequent)} t·∫≠p ph·ªï bi·∫øn")
                else:
                    st.warning("Kh√¥ng t√¨m th·∫•y itemsets ph·ªï bi·∫øn. H√£y gi·∫£m min_support.")
                
                st.write("**Lu·∫≠t li√™n k·∫øt s·∫£n ph·∫©m:**")
                if not rules.empty:
                    st.dataframe(rules)
                    
                    # Ph√¢n t√≠ch k·∫øt qu·∫£
                    st.write("**Ph√¢n T√≠ch K·∫øt Qu·∫£:**")
                    for i, row in rules.iterrows():
                        st.write(f"‚Ä¢ N·∫øu kh√°ch mua **{row['antecedents']}** ‚Üí {row['confidence']:.1%} kh·∫£ nƒÉng mua **{row['consequents']}** (lift={row['lift']:.1f})")
                        st.write(f"  ‚Üí *G·ª£i √Ω:* B·ªë tr√≠ 2 s·∫£n ph·∫©m n√†y g·∫ßn nhau tr√™n k·ªá")
                else:
                    st.warning("Kh√¥ng t√¨m th·∫•y lu·∫≠t li√™n k·∫øt n√†o. H√£y th·ª≠ gi·∫£m min_support ho·∫∑c min_confidence.")
            else:
                st.error("D·ªØ li·ªáu kh√¥ng c√≥ c·ªôt 'Customer Reference ID' ho·∫∑c 'Item Purchased'")

    elif algo == "Rough Set":
        st.subheader("Thu·∫≠t to√°n t·∫≠p th√¥ (Rough Set)")
        st.write("**B√†i to√°n:** Ph√¢n T√≠ch Y·∫øu T·ªë ·∫¢nh H∆∞·ªüng ƒê√°nh Gi√°")
        st.write("**M·ª•c ti√™u:** T√¨m nh·ªØng y·∫øu t·ªë c·ªët l√µi ·∫£nh h∆∞·ªüng ƒë·∫øn vi·ªác kh√°ch h√†ng ƒë·ªÉ l·∫°i ƒë√°nh gi√° t·ªët (Review Rating cao)")
        
        if 'Review Rating' in data_df.columns:
            # Hi·ªÉn th·ªã d·ªØ li·ªáu ƒë·∫ßu v√†o
            from src.roughset import analyze_review_factors
            
            # Chu·∫©n b·ªã d·ªØ li·ªáu ƒë·ªÉ hi·ªÉn th·ªã
            analysis_data = data_df.dropna(subset=['Review Rating']).copy()
            analysis_data['High_Rating'] = (analysis_data['Review Rating'] >= 4.0).astype(int)
            
            # X·ª≠ l√Ω missing values cho c√°c c·ªôt hi·ªÉn th·ªã
            if 'Item Purchased' in analysis_data.columns:
                analysis_data['Item Purchased'] = analysis_data['Item Purchased'].fillna('Unknown')
            if 'Payment Method' in analysis_data.columns:
                analysis_data['Payment Method'] = analysis_data['Payment Method'].fillna('Unknown')
            if 'Purchase Amount (USD)' in analysis_data.columns:
                if analysis_data['Purchase Amount (USD)'].notna().any():
                    median_val = analysis_data['Purchase Amount (USD)'].median()
                    analysis_data['Purchase Amount (USD)'] = analysis_data['Purchase Amount (USD)'].fillna(median_val)
                else:
                    analysis_data['Purchase Amount (USD)'] = analysis_data['Purchase Amount (USD)'].fillna(0)
            
            # Ch·ªçn c√°c c·ªôt c·ªët l√µi ƒë·ªÉ hi·ªÉn th·ªã
            display_cols = []
            if 'Item Purchased' in analysis_data.columns:
                display_cols.append('Item Purchased')
            if 'Payment Method' in analysis_data.columns:
                display_cols.append('Payment Method')
            if 'Purchase Amount (USD)' in analysis_data.columns:
                display_cols.append('Purchase Amount (USD)')
            display_cols.extend(['Review Rating', 'High_Rating'])
            
            st.write("**D·ªØ li·ªáu ƒë·∫ßu v√†o:**")
            st.dataframe(analysis_data[display_cols].head(20))
            
            if st.button("Ch·∫°y Rough Set"):
                # Ph√¢n t√≠ch c√°c y·∫øu t·ªë
                insights = analyze_review_factors(data_df)
                
                st.subheader("C√°c Y·∫øu T·ªë C·ªët L√µi ·∫¢nh H∆∞·ªüng ƒê√°nh Gi√°:")
                for i, factor in enumerate(insights['important_factors'], 1):
                    st.write(f"**{i}. {factor}**")
                
                # Th·ªëng k√™ t·ªïng quan
                st.subheader("Th·ªëng K√™ T·ªïng Quan:")
                summary = insights['summary']
                col1, col2, col3 = st.columns(3)
                with col1:
                    st.metric("T·ªïng s·ªë ƒë√°nh gi√°", summary['total_reviews'])
                with col2:
                    st.metric("ƒê√°nh gi√° t·ªët", f"{summary['high_rating_count']} ({summary['high_rating_rate']:.1%})")
                with col3:
                    st.metric("ƒê√°nh gi√° trung b√¨nh", f"{summary['avg_rating']}/5.0")
                
                # Ph√¢n t√≠ch chi ti·∫øt t·ª´ng y·∫øu t·ªë
                st.subheader("Ph√¢n T√≠ch Chi Ti·∫øt C√°c Y·∫øu T·ªë:")
                for i, factor in enumerate(insights['important_factors'], 1):
                    st.write(f"**{i}. {factor}**")
                    
                    factor_info = insights['factor_analysis'][factor]
                    
                    if factor_info['type'] == 'categorical':
                        # Y·∫øu t·ªë categorical
                        st.write(f"**Lo·∫°i t·ªët nh·∫•t:** {factor_info['best_category']} ({factor_info['best_rate']:.1%} ƒë√°nh gi√° t·ªët)")
                        st.write("**Chi ti·∫øt theo t·ª´ng lo·∫°i:**")
                        
                        details = factor_info['details']
                        if details:  # Ki·ªÉm tra n·∫øu c√≥ d·ªØ li·ªáu
                            for category, stats in details.items():
                                if isinstance(stats, dict) and 'Total_Reviews' in stats:
                                    total = stats['Total_Reviews']
                                    rate = stats['High_Rating_Rate']
                                    st.write(f"‚Ä¢ **{category}**: {total} ƒë√°nh gi√°, {rate:.1%} t·ªët")
                                else:
                                    st.write(f"‚Ä¢ **{category}**: D·ªØ li·ªáu kh√¥ng h·ª£p l·ªá")
                        else:
                            st.write("‚Ä¢ Kh√¥ng c√≥ d·ªØ li·ªáu chi ti·∫øt")
                            
                    else:
                        # Y·∫øu t·ªë numerical
                        st.write("**So s√°nh gi√° tr·ªã trung b√¨nh:**")
                        st.write(f"‚Ä¢ ƒê√°nh gi√° t·ªët (‚â•4.0): **{factor_info['high_rating_avg']}**")
                        st.write(f"‚Ä¢ ƒê√°nh gi√° th·∫•p (<4.0): **{factor_info['low_rating_avg']}**")
                        st.write(f"‚Ä¢ Ch√™nh l·ªách: **{factor_info['difference']}** ({factor_info['impact']})")
                    
                    st.write("---")
                
                # ƒê·ªÅ xu·∫•t
                st.subheader("ƒê·ªÅ xu·∫•t:")
                for recommendation in insights['recommendations']:
                    st.write(f"‚Ä¢ {recommendation}")
        else:
            st.error("D·ªØ li·ªáu kh√¥ng c√≥ c·ªôt 'Review Rating'")

    else:
        st.info("Ch·ªçn thu·∫≠t to√°n ·ªü sidebar ƒë·ªÉ ch·∫°y.")


if __name__ == "__main__":
    main()


